{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfernandes10/MetNumUN2023I/blob/main/Lab7/week_4_iterative_linalg_Jacobi_Seidel_minresGroup23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Grupo 23\n",
        "\n",
        "Mario Fernandez.\n",
        "\n",
        "Diego Vesga.\n",
        "\n",
        "Ivan Sepulveda.\n",
        "\n"
      ],
      "metadata": {
        "id": "27tEI3atUacT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJIL7nVSVaD9"
      },
      "source": [
        "# Simple iteration for systems of linear equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9pI5FUoVaEA"
      },
      "source": [
        "First, generate a random diagonally dominant matrix, for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "UnP6tWKEVaEA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rndm = np.random.RandomState(1234)\n",
        "\n",
        "n = 10\n",
        "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
        "b = rndm.uniform(size=n)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "id": "ZMBXoxayL0hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c34072-b95d-45f8-cc80-92f2d06ab5a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.51915195e+01, 6.22108771e-01, 4.37727739e-01, 7.85358584e-01,\n",
              "        7.79975808e-01, 2.72592605e-01, 2.76464255e-01, 8.01872178e-01,\n",
              "        9.58139354e-01, 8.75932635e-01],\n",
              "       [3.57817270e-01, 1.55009951e+01, 6.83462935e-01, 7.12702027e-01,\n",
              "        3.70250755e-01, 5.61196186e-01, 5.03083165e-01, 1.37684496e-02,\n",
              "        7.72826622e-01, 8.82641191e-01],\n",
              "       [3.64885984e-01, 6.15396178e-01, 1.50753812e+01, 3.68824006e-01,\n",
              "        9.33140102e-01, 6.51378143e-01, 3.97202578e-01, 7.88730143e-01,\n",
              "        3.16836122e-01, 5.68098653e-01],\n",
              "       [8.69127390e-01, 4.36173424e-01, 8.02147642e-01, 1.51437668e+01,\n",
              "        7.04260971e-01, 7.04581308e-01, 2.18792106e-01, 9.24867629e-01,\n",
              "        4.42140755e-01, 9.09315959e-01],\n",
              "       [5.98092228e-02, 1.84287084e-01, 4.73552788e-02, 6.74880944e-01,\n",
              "        1.55946248e+01, 5.33310163e-01, 4.33240627e-02, 5.61433080e-01,\n",
              "        3.29668446e-01, 5.02966833e-01],\n",
              "       [1.11894318e-01, 6.07193706e-01, 5.65944643e-01, 6.76406199e-03,\n",
              "        6.17441709e-01, 1.59121229e+01, 7.90524133e-01, 9.92081466e-01,\n",
              "        9.58801762e-01, 7.91964135e-01],\n",
              "       [2.85250960e-01, 6.24916705e-01, 4.78093796e-01, 1.95675179e-01,\n",
              "        3.82317452e-01, 5.38736851e-02, 1.54516484e+01, 9.82004742e-01,\n",
              "        1.23942700e-01, 1.19380898e-01],\n",
              "       [7.38523056e-01, 5.87303633e-01, 4.71632534e-01, 1.07126817e-01,\n",
              "        2.29218565e-01, 8.99965195e-01, 4.16753538e-01, 1.55358517e+01,\n",
              "        6.20851659e-03, 3.00641706e-01],\n",
              "       [4.36893172e-01, 6.12148997e-01, 9.18198075e-01, 6.25736670e-01,\n",
              "        7.05997565e-01, 1.49833716e-01, 7.46063409e-01, 8.31006992e-01,\n",
              "        1.56337258e+01, 4.38309881e-01],\n",
              "       [1.52572775e-01, 5.68409615e-01, 5.28224278e-01, 9.51428764e-01,\n",
              "        4.80359179e-01, 5.02559563e-01, 5.36878193e-01, 8.19202067e-01,\n",
              "        5.71156381e-02, 1.56694217e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggTw4saqVaEB"
      },
      "source": [
        "# I.  Jacobi iteration\n",
        "\n",
        "Given\n",
        "\n",
        "$$\n",
        "A x = b\n",
        "$$\n",
        "\n",
        "separate the diagonal part $D$,\n",
        "\n",
        "$$ A = D + (A - D) $$\n",
        "\n",
        "and write\n",
        "\n",
        "$$\n",
        "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
        "$$\n",
        "\n",
        "Then iterate\n",
        "\n",
        "$$\n",
        "x_{n + 1} = B x_{n} + c\\;,\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$$\n",
        "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D5bAWgRVaEC"
      },
      "source": [
        "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mb0EdEPKVaEC"
      },
      "outputs": [],
      "source": [
        "diag_1d = np.diag(A)\n",
        "\n",
        "B = -A.copy()\n",
        "np.fill_diagonal(B, 0)\n",
        "\n",
        "D = np.diag(diag_1d)\n",
        "invD = np.diag(1./diag_1d)\n",
        "BB = invD @ B \n",
        "c = invD @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TljkquZSVaED"
      },
      "outputs": [],
      "source": [
        "# sanity checks\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "assert_allclose(-B + D, A)\n",
        "\n",
        "\n",
        "# xx is a \"ground truth\" solution, compute it using a direct method\n",
        "xx = np.linalg.solve(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@xx, b)\n",
        "np.testing.assert_allclose(D@xx, B@xx + b)\n",
        "np.testing.assert_allclose(xx, BB@xx + c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww6QntiDVaED"
      },
      "source": [
        "Check that $\\| B\\| \\leqslant 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YwYX-A8VaEE",
        "outputId": "e2de1ba5-6c92-457f-883d-fa37547fad99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36436161983015336"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "np.linalg.norm(BB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4k4qwJIVaEF"
      },
      "source": [
        "# Do the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "DkVhz4rWVaEF"
      },
      "outputs": [],
      "source": [
        "n_iter = 50\n",
        "\n",
        "x0 = np.ones(n)\n",
        "x = x0\n",
        "for _ in range(n_iter):\n",
        "    x = BB @ x + c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpm38tDiVaEF",
        "outputId": "fd549bd9-c575-4906-da7e-9808568c5f6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
              "        1.11022302e-16,  0.00000000e+00, -2.42861287e-17,  0.00000000e+00,\n",
              "       -2.77555756e-17,  1.11022302e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Check the result:\n",
        "\n",
        "A @ x - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmHrRfAOVaEG"
      },
      "source": [
        "### Task I.1\n",
        "\n",
        "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
        "\n",
        "\n",
        "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
        "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
        "\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "lrY1-p4pVaEG"
      },
      "outputs": [],
      "source": [
        "def jacobi_iteration(A, b, eps = 1e-7, n_iter = 50):\n",
        "  diag = np.diag(A)\n",
        "  B = -A.copy()\n",
        "  np.fill_diagonal(B, 0)\n",
        "  inv = np.diag(1./diag_1d)\n",
        "  BB = inv @ B \n",
        "  c = inv @ b\n",
        "  x_0 = np.ones(n)\n",
        "  for _ in range(n_iter):\n",
        "    x_0 = BB @ x + c\n",
        "  return x_0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 16):\n",
        "    A1 = A + np.diagflat([-i]*n)\n",
        "    print(np.linalg.norm(np.diag(1./np.diag(A1))@(-A1.copy()+np.diag(np.diag(A1)))),\n",
        "          np.linalg.norm(jacobi_iteration(A1, b)-np.linalg.solve(A1, b)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIouU4xLWju0",
        "outputId": "9fe9bfb6-2252-4c7d-eaf0-a49eaed981ba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.38959181027260875 0.006748907329509937\n",
            "0.4185783948614869 0.014404905186773016\n",
            "0.4522284025473819 0.023173930652707595\n",
            "0.4917667095178099 0.03333264055689647\n",
            "0.5388887887486234 0.045262992502026825\n",
            "0.5960110344093966 0.059510009720590076\n",
            "0.6667001660296402 0.0768835469371436\n",
            "0.7564517359241753 0.09864963390538432\n",
            "0.8742017351588476 0.12692079839179277\n",
            "1.0355299928250665 0.16554077621839597\n",
            "1.2702850939751231 0.22239785467784945\n",
            "1.6439565658213244 0.31688293273593565\n",
            "2.334809111760855 0.5141531579855976\n",
            "4.080768845910033 1.2768381766268402\n",
            "30.715327603064885 1.7776027746926315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1wOqW4nVaEG"
      },
      "source": [
        "# II. Seidel's iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUDvDOmVaEG"
      },
      "source": [
        "##### Task II.1\n",
        "\n",
        "Implement the Seidel's iteration. \n",
        "\n",
        "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "XjhKy9JtVaEH"
      },
      "outputs": [],
      "source": [
        "def seidel_iteration(A, b, eps = 1e-7, n_iter = 50):\n",
        "  x = np.ones(b.shape[0])\n",
        "  for _ in range(n_iter):\n",
        "    for i in range(b.shape[0]):\n",
        "      x[i] = (b[i]-np.dot(A[i][:i], x[:i])- np.dot(A[i][i+1:], x[i+1:]))/A[i,i]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 16):\n",
        "    B1 = A + np.diagflat([-i]*n)\n",
        "    print(np.linalg.norm(np.diag(1./np.diag(B1))@(-B1.copy()+np.diag(np.diag(B1)))),\n",
        "          np.linalg.norm(seidel_iteration(B1, b)-np.linalg.solve(B1, b)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9WFDRZXjrL",
        "outputId": "4679edd2-a71e-43dc-e0a8-60b4bf9e3b0d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.38959181027260875 1.5540063044689707e-17\n",
            "0.4185783948614869 2.303412968156487e-17\n",
            "0.4522284025473819 3.3107778123195866e-17\n",
            "0.4917667095178099 1.717836144195444e-17\n",
            "0.5388887887486234 1.8703665918870363e-17\n",
            "0.5960110344093966 2.6208106743381504e-17\n",
            "0.6667001660296402 3.222105849667643e-17\n",
            "0.7564517359241753 3.894444544739273e-17\n",
            "0.8742017351588476 4.3610271956070115e-17\n",
            "1.0355299928250665 7.521581756278068e-17\n",
            "1.2702850939751231 6.691626947686432e-17\n",
            "1.6439565658213244 1.0829177162645093e-16\n",
            "2.334809111760855 1.1775693440128312e-16\n",
            "4.080768845910033 4.10633611443092e-09\n",
            "30.715327603064885 2.224327617064848e+114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqyL6nCmVaEH"
      },
      "source": [
        "# III. Minimum residual scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6f0heoVaEH"
      },
      "source": [
        "### Task III.1\n",
        "\n",
        "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
        "\n",
        "(50% of the grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "hD0xbglGVaEH"
      },
      "outputs": [],
      "source": [
        "def minimum_residual(A, b, eps = 1e-7, n_iter = 50):\n",
        "  x = np.ones(b.shape[0])\n",
        "  for _ in range(n_iter):\n",
        "    r = A @ x - b\n",
        "    k = (r @ A @ r)/np.linalg.norm(A @ r)**2\n",
        "    x = x - k*r\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 16):\n",
        "    C1 = A + np.diagflat([-i]*n)\n",
        "    print(np.linalg.norm(np.diag(1./np.diag(C1))@(-C1.copy()+np.diag(np.diag(C1)))),\n",
        "          np.linalg.norm(minimum_residual(C1, b)-np.linalg.solve(C1, b)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz1E1-5kXwET",
        "outputId": "c21248a5-efc9-4409-ced0-d353e856e89d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.38959181027260875 2.224517603584333e-17\n",
            "0.4185783948614869 2.32747678105055e-17\n",
            "0.4522284025473819 3.7570382170898963e-17\n",
            "0.4917667095178099 3.1524751290996645e-17\n",
            "0.5388887887486234 1.6016862586769483e-17\n",
            "0.5960110344093966 2.2882574235218375e-17\n",
            "0.6667001660296402 3.309641454705087e-17\n",
            "0.7564517359241753 nan\n",
            "0.8742017351588476 4.4969172124985776e-17\n",
            "1.0355299928250665 6.331146576060244e-17\n",
            "1.2702850939751231 6.177174679671291e-17\n",
            "1.6439565658213244 1.0362341316682908e-16\n",
            "2.334809111760855 1.0820341707075497e-13\n",
            "4.080768845910033 0.0002171791368378776\n",
            "30.715327603064885 2.0818042350846104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-707485f5b6e2>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  k = (r @ A @ r)/np.linalg.norm(A @ r)**2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}